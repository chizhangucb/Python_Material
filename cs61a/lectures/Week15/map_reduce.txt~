MapReduce is a framework for batch processing of Big Data.

- Framework: A system used by programmers to build applications.
- Batch processing: All the data is available at the outset, and results aren't used until processing completes.
- Big Data: Used to describte data sets so large that they can reveal new facts about the world, usually from statistical analysis.

The mapreduce idea:
- data sets are too big to be analyzed by one machine.
- using multiple machines has the same complications, regardless of the application.
- pure functions enable an abstraction barrier between data processing logic and coordinating a distributed application.

Constraints on the mapper and reducer:
- The mapper must be equivalent to applying a deterministic pure function to each input independently.
- The reducer must be equivalent to applying a deterministic pure function to the sequence of values for each key.
